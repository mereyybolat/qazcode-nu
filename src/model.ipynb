{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hackathon Pipeline From Scratch (Offline)\n",
        "\n",
        "Цель: обучить локальный pipeline для `Symptoms -> Top-3 ICD-10` без внешних API.\n",
        "\n",
        "Что делаем:\n",
        "1. Libraries\n",
        "2. Data load + head\n",
        "3. Preprocessing\n",
        "4. Train/test split\n",
        "5. Train models\n",
        "6. Evaluate (`Accuracy@1`, `Recall@3`)\n",
        "7. Final `diagnose()` function in hackathon format\n",
        "8. Save artifacts for server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import re\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Data Load + Data Head\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_project_root() -> Path:\n",
        "    candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
        "    for c in candidates:\n",
        "        if (c / 'data' / 'test_set').exists():\n",
        "            return c\n",
        "    raise FileNotFoundError('Could not find data/test_set from current working directory.')\n",
        "\n",
        "ROOT = find_project_root()\n",
        "DATA_DIR = ROOT / 'data' / 'test_set'\n",
        "\n",
        "records: list[dict[str, Any]] = []\n",
        "for p in sorted(DATA_DIR.glob('*.json')):\n",
        "    with p.open('r', encoding='utf-8') as f:\n",
        "        obj = json.load(f)\n",
        "    obj['_path'] = str(p)\n",
        "    records.append(obj)\n",
        "\n",
        "print('Loaded records:', len(records))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "for r in records:\n",
        "    rows.append({\n",
        "        'protocol_id': r.get('protocol_id'),\n",
        "        'query': r.get('query'),\n",
        "        'gt': r.get('gt'),\n",
        "        'num_valid_icd_codes': len(r.get('icd_codes', [])),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print('Shape:', df.shape)\n",
        "df.head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# quick class distribution check\n",
        "class_counts = df['gt'].value_counts()\n",
        "print('Unique target classes:', class_counts.shape[0])\n",
        "print('Top 15 frequent classes:')\n",
        "class_counts.head(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TOKEN_RE = re.compile(r'[a-zа-я0-9]+', flags=re.IGNORECASE)\n",
        "STOPWORDS = {\n",
        "    'и', 'в', 'во', 'на', 'по', 'с', 'со', 'к', 'ко', 'у', 'о', 'об', 'от', 'до', 'за',\n",
        "    'что', 'как', 'это', 'а', 'но', 'или', 'не', 'нет', 'есть', 'уже', 'еще', 'очень',\n",
        "    'the', 'a', 'an', 'and', 'or', 'to', 'of', 'for', 'in', 'on', 'is', 'are'\n",
        "}\n",
        "\n",
        "def normalize_text(text: Any) -> str:\n",
        "    if text is None:\n",
        "        return ''\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    tokens = [t.lower() for t in TOKEN_RE.findall(text)]\n",
        "    tokens = [t for t in tokens if len(t) > 2 and t not in STOPWORDS]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "X = [normalize_text(r.get('query')) for r in records]\n",
        "y = [str(r.get('gt', '')) for r in records]\n",
        "valid_sets = [set(r.get('icd_codes', [])) for r in records]\n",
        "\n",
        "print('Empty normalized queries:', sum(1 for t in X if not t))\n",
        "print('Total samples:', len(X))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Train/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stratify only if every class appears at least twice\n",
        "counts = Counter(y)\n",
        "can_stratify = all(v >= 2 for v in counts.values())\n",
        "\n",
        "X_train, X_test, y_train, y_test, valid_train, valid_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    valid_sets,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y if can_stratify else None,\n",
        ")\n",
        "\n",
        "print('Train size:', len(X_train))\n",
        "print('Test size :', len(X_test))\n",
        "print('Stratify  :', can_stratify)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Creating + Training the Model (Ensemble)\n",
        "\n",
        "Мы обучим 2 модели и объединим вероятности:\n",
        "- Model A: word n-grams TF-IDF + Logistic Regression\n",
        "- Model B: char n-grams TF-IDF + Logistic Regression\n",
        "\n",
        "Почему это работает:\n",
        "- word-модель ловит медицинские термины,\n",
        "- char-модель устойчивее к опечаткам/морфологии.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "word_model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_features=50000, sublinear_tf=True)),\n",
        "    ('clf', LogisticRegression(max_iter=2500, C=2.0, multi_class='auto')),\n",
        "])\n",
        "\n",
        "char_model = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=1, max_features=80000, sublinear_tf=True)),\n",
        "    ('clf', LogisticRegression(max_iter=2500, C=1.2, multi_class='auto')),\n",
        "])\n",
        "\n",
        "word_model.fit(X_train, y_train)\n",
        "char_model.fit(X_train, y_train)\n",
        "\n",
        "print('Both models trained.')\n",
        "print('Num classes:', len(word_model.classes_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Evaluating (Accuracy, Recall)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def blend_proba(word_proba: np.ndarray, char_proba: np.ndarray, alpha: float = 0.65) -> np.ndarray:\n",
        "    # alpha for word model, (1-alpha) for char model\n",
        "    return alpha * word_proba + (1.0 - alpha) * char_proba\n",
        "\n",
        "word_proba_test = word_model.predict_proba(X_test)\n",
        "char_proba_test = char_model.predict_proba(X_test)\n",
        "blend_test = blend_proba(word_proba_test, char_proba_test, alpha=0.65)\n",
        "classes = word_model.classes_\n",
        "\n",
        "# Top-1 metrics\n",
        "pred_top1 = classes[np.argmax(blend_test, axis=1)]\n",
        "acc1 = accuracy_score(y_test, pred_top1)\n",
        "recall_macro = recall_score(y_test, pred_top1, average='macro', zero_division=0)\n",
        "\n",
        "print(f'Accuracy@1: {acc1*100:.2f}%')\n",
        "print(f'Recall (macro): {recall_macro*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Challenge-style Recall@3\n",
        "\n",
        "def top_k_from_proba(proba: np.ndarray, classes: np.ndarray, k: int = 3) -> list[list[str]]:\n",
        "    out = []\n",
        "    for row in proba:\n",
        "        idx = np.argsort(row)[-k:][::-1]\n",
        "        out.append([str(classes[i]) for i in idx])\n",
        "    return out\n",
        "\n",
        "top3 = top_k_from_proba(blend_test, classes, k=3)\n",
        "hits = 0\n",
        "for preds, valid in zip(top3, valid_test):\n",
        "    if any(code in valid for code in preds):\n",
        "        hits += 1\n",
        "\n",
        "recall_at_3 = hits / len(top3)\n",
        "print(f'Recall@3 (challenge): {recall_at_3*100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Final Inference Function (`diagnose`)\n",
        "\n",
        "Формат совместим с `evaluate.py`:\n",
        "```json\n",
        "{\"diagnoses\": [{\"rank\": 1, \"diagnosis\": \"...\", \"icd10_code\": \"...\", \"explanation\": \"...\"}]}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrain on ALL available data for final inference\n",
        "word_model_full = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), min_df=1, max_features=50000, sublinear_tf=True)),\n",
        "    ('clf', LogisticRegression(max_iter=2500, C=2.0, multi_class='auto')),\n",
        "])\n",
        "\n",
        "char_model_full = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(analyzer='char_wb', ngram_range=(3, 5), min_df=1, max_features=80000, sublinear_tf=True)),\n",
        "    ('clf', LogisticRegression(max_iter=2500, C=1.2, multi_class='auto')),\n",
        "])\n",
        "\n",
        "word_model_full.fit(X, y)\n",
        "char_model_full.fit(X, y)\n",
        "\n",
        "code_frequency = Counter(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diagnose(symptoms: str, top_k: int = 3, alpha: float = 0.65) -> dict[str, Any]:\n",
        "    text = normalize_text(symptoms)\n",
        "\n",
        "    if not text:\n",
        "        fallback = [c for c, _ in code_frequency.most_common(top_k)]\n",
        "        return {\n",
        "            'diagnoses': [\n",
        "                {\n",
        "                    'rank': i + 1,\n",
        "                    'diagnosis': f'Likely ICD-10 category {code}',\n",
        "                    'icd10_code': code,\n",
        "                    'explanation': 'Fallback for empty symptoms input.'\n",
        "                }\n",
        "                for i, code in enumerate(fallback)\n",
        "            ]\n",
        "        }\n",
        "\n",
        "    wp = word_model_full.predict_proba([text])[0]\n",
        "    cp = char_model_full.predict_proba([text])[0]\n",
        "    bp = alpha * wp + (1.0 - alpha) * cp\n",
        "\n",
        "    classes = word_model_full.classes_\n",
        "    idx = np.argsort(bp)[-top_k:][::-1]\n",
        "\n",
        "    diagnoses = []\n",
        "    for rank, i in enumerate(idx, start=1):\n",
        "        code = str(classes[i])\n",
        "        conf = float(bp[i])\n",
        "        diagnoses.append({\n",
        "            'rank': rank,\n",
        "            'diagnosis': f'Probable condition mapped to {code}',\n",
        "            'icd10_code': code,\n",
        "            'explanation': f'Offline ensemble baseline (word+char TF-IDF), confidence={conf:.3f}.'\n",
        "        })\n",
        "\n",
        "    return {'diagnoses': diagnoses}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Smoke test\n",
        "example = records[0].get('query', '')\n",
        "pred = diagnose(example, top_k=3)\n",
        "print(json.dumps(pred, ensure_ascii=False, indent=2)[:1500])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Save Model Artifacts (for mock_server integration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ARTIFACT_DIR = ROOT / 'artifacts'\n",
        "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "artifact_path = ARTIFACT_DIR / 'offline_ensemble_icd10.joblib'\n",
        "joblib.dump({\n",
        "    'word_model': word_model_full,\n",
        "    'char_model': char_model_full,\n",
        "    'alpha': 0.65,\n",
        "    'code_frequency': code_frequency,\n",
        "}, artifact_path)\n",
        "\n",
        "print('Saved:', artifact_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Step\n",
        "\n",
        "Подключить `artifacts/offline_ensemble_icd10.joblib` в `src/mock_server.py` и использовать `diagnose()`-логику в эндпоинте `/diagnose`.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}