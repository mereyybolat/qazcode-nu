{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# QazCode Hackathon: Simple LLM Baseline\n",
        "\n",
        "Цель: по симптомам вернуть `top-N` диагнозов с `ICD-10` в формате, совместимом с `evaluate.py`.\n",
        "\n",
        "Пайплайн:\n",
        "1. Загружаем `data/test_set` и строим простой retrieval по текстам запросов.\n",
        "2. Выбираем кандидаты ICD локально (быстро и стабильно).\n",
        "3. Передаем только кандидатов в LLM (`oss-120b`), чтобы ранжировать top-3.\n",
        "4. Возвращаем JSON c `diagnoses: [{rank, diagnosis, icd10_code, explanation}]`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import statistics\n",
        "import time\n",
        "from collections import Counter, defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "\n",
        "from openai import OpenAI\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Настройка LLM API\n",
        "\n",
        "Не сохраняйте ключ в git. Используйте переменные окружения.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Вставьте ключ один раз в текущей сессии ноутбука\n",
        "# os.environ['QAZCODE_API_KEY'] = 'sk-...'<- не коммитить\n",
        "\n",
        "HUB_URL = os.getenv('QAZCODE_HUB_URL', 'https://hub.qazcode.ai')\n",
        "API_KEY = os.getenv('QAZCODE_API_KEY', '')\n",
        "MODEL = os.getenv('QAZCODE_MODEL', 'oss-120b')\n",
        "\n",
        "if not API_KEY:\n",
        "    raise ValueError('Set QAZCODE_API_KEY in environment before running this notebook.')\n",
        "\n",
        "client = OpenAI(base_url=HUB_URL, api_key=API_KEY)\n",
        "print('Client ready:', HUB_URL, 'model=', MODEL)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Загрузка данных\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_project_root() -> Path:\n",
        "    candidates = [Path.cwd(), Path.cwd().parent, Path.cwd().parent.parent]\n",
        "    for c in candidates:\n",
        "        if (c / 'data' / 'test_set').exists():\n",
        "            return c\n",
        "    raise FileNotFoundError('Could not find data/test_set from current working dir.')\n",
        "\n",
        "ROOT = find_project_root()\n",
        "DATA_DIR = ROOT / 'data' / 'test_set'\n",
        "\n",
        "records: list[dict[str, Any]] = []\n",
        "for p in sorted(DATA_DIR.glob('*.json')):\n",
        "    with p.open('r', encoding='utf-8') as f:\n",
        "        obj = json.load(f)\n",
        "    obj['_path'] = str(p)\n",
        "    records.append(obj)\n",
        "\n",
        "print('Loaded records:', len(records))\n",
        "all_codes = sorted({r['gt'] for r in records})\n",
        "print('Unique GT codes:', len(all_codes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Простой retrieval для ICD кандидатов\n",
        "\n",
        "Идея: ищем похожие симптомы по токенам и берем самые частые `gt` у соседей.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TOKEN_RE = re.compile(r'[a-zа-я0-9]+', flags=re.IGNORECASE)\n",
        "STOPWORDS = {\n",
        "    'и', 'в', 'во', 'на', 'по', 'с', 'со', 'к', 'ко', 'у', 'о', 'об', 'от', 'до', 'за',\n",
        "    'что', 'как', 'это', 'а', 'но', 'или', 'не', 'нет', 'есть', 'уже', 'еще', 'очень',\n",
        "    'the', 'a', 'an', 'and', 'or', 'to', 'of', 'for', 'in', 'on', 'is', 'are'\n",
        "}\n",
        "\n",
        "def tokenize(text: Any) -> list[str]:\n",
        "    if text is None:\n",
        "        return []\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text)\n",
        "    toks = [t.lower() for t in TOKEN_RE.findall(text)]\n",
        "    return [t for t in toks if len(t) > 2 and t not in STOPWORDS]\n",
        "\n",
        "def to_counter(text: Any) -> Counter:\n",
        "    return Counter(tokenize(text))\n",
        "\n",
        "query_vectors: list[Counter] = []\n",
        "for r in records:\n",
        "    query_vectors.append(to_counter(r.get('query', '')))\n",
        "\n",
        "def weighted_jaccard(a: Counter, b: Counter) -> float:\n",
        "    if not a or not b:\n",
        "        return 0.0\n",
        "    keys = set(a) | set(b)\n",
        "    inter = sum(min(a[k], b[k]) for k in keys)\n",
        "    union = sum(max(a[k], b[k]) for k in keys)\n",
        "    return inter / union if union else 0.0\n",
        "\n",
        "def retrieve_candidate_codes(symptoms: str, k_neighbors: int = 20, top_codes: int = 20) -> list[str]:\n",
        "    qv = to_counter(symptoms)\n",
        "    scored = []\n",
        "    for i, rv in enumerate(query_vectors):\n",
        "        s = weighted_jaccard(qv, rv)\n",
        "        if s > 0:\n",
        "            scored.append((s, records[i]['gt']))\n",
        "\n",
        "    scored.sort(reverse=True, key=lambda x: x[0])\n",
        "    neighbors = scored[:k_neighbors]\n",
        "\n",
        "    code_score = defaultdict(float)\n",
        "    for rank, (sim, code) in enumerate(neighbors, start=1):\n",
        "        code_score[code] += sim / rank\n",
        "\n",
        "    if not code_score:\n",
        "        # fallback: самые частые коды в датасете\n",
        "        freq = Counter(r['gt'] for r in records)\n",
        "        return [c for c, _ in freq.most_common(top_codes)]\n",
        "\n",
        "    best = sorted(code_score.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [c for c, _ in best[:top_codes]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Вызов LLM и строгий JSON парсинг\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = (\n",
        "    'You are a clinical ICD-10 triage assistant. '\n",
        "    'Return ONLY valid JSON with key diagnoses. '\n",
        "    'Each item must contain: rank (int), diagnosis (string), icd10_code (string), explanation (string). '\n",
        "    'Use only ICD-10 codes from candidate_codes. '\n",
        ")\n",
        "\n",
        "def _safe_json_extract(text: str) -> dict[str, Any]:\n",
        "    text = text.strip()\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        m = re.search(r'\\{.*\\}', text, flags=re.DOTALL)\n",
        "        if not m:\n",
        "            raise\n",
        "        return json.loads(m.group(0))\n",
        "\n",
        "def llm_rank(symptoms: str, candidate_codes: list[str], top_k: int = 3) -> list[dict[str, Any]]:\n",
        "    user_prompt = {\n",
        "        'task': 'Given symptoms, rank most likely ICD-10 diagnoses',\n",
        "        'symptoms': symptoms,\n",
        "        'candidate_codes': candidate_codes,\n",
        "        'top_k': top_k,\n",
        "        'output_schema': {\n",
        "            'diagnoses': [\n",
        "                {'rank': 1, 'diagnosis': '...', 'icd10_code': '...', 'explanation': '...'}\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        temperature=0.1,\n",
        "        messages=[\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "            {'role': 'user', 'content': json.dumps(user_prompt, ensure_ascii=False)},\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    content = resp.choices[0].message.content or '{}'\n",
        "    obj = _safe_json_extract(content)\n",
        "    diagnoses = obj.get('diagnoses', [])\n",
        "\n",
        "    cleaned = []\n",
        "    for i, d in enumerate(diagnoses[:top_k], start=1):\n",
        "        code = str(d.get('icd10_code', '')).strip()\n",
        "        if code not in candidate_codes:\n",
        "            continue\n",
        "        cleaned.append({\n",
        "            'rank': i,\n",
        "            'diagnosis': str(d.get('diagnosis', 'Unknown diagnosis'))[:200],\n",
        "            'icd10_code': code,\n",
        "            'explanation': str(d.get('explanation', ''))[:500],\n",
        "        })\n",
        "\n",
        "    # fallback если LLM вернул мало/плохой JSON\n",
        "    if len(cleaned) < top_k:\n",
        "        used = {d['icd10_code'] for d in cleaned}\n",
        "        for c in candidate_codes:\n",
        "            if c in used:\n",
        "                continue\n",
        "            cleaned.append({\n",
        "                'rank': len(cleaned) + 1,\n",
        "                'diagnosis': f'Probable condition for {c}',\n",
        "                'icd10_code': c,\n",
        "                'explanation': 'Fallback from retrieval candidate list.',\n",
        "            })\n",
        "            if len(cleaned) >= top_k:\n",
        "                break\n",
        "\n",
        "    return cleaned[:top_k]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Главная функция предсказания (формат evaluate.py)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diagnose(symptoms: str, top_k: int = 3, n_candidates: int = 20) -> dict[str, Any]:\n",
        "    candidates = retrieve_candidate_codes(symptoms, top_codes=n_candidates)\n",
        "    ranked = llm_rank(symptoms, candidates, top_k=top_k)\n",
        "    return {'diagnoses': ranked}\n",
        "\n",
        "# smoke test\n",
        "example_symptoms = records[0]['query']\n",
        "result = diagnose(example_symptoms, top_k=3)\n",
        "print(json.dumps(result, ensure_ascii=False, indent=2)[:1500])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Быстрая локальная проверка на части датасета\n",
        "\n",
        "Важно: это proxy-оценка на публичных данных, а не финальный holdout leaderboard.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_subset(sample_size: int = 25, seed: int = 42) -> dict[str, Any]:\n",
        "    rng = random.Random(seed)\n",
        "    subset = records[:]\n",
        "    rng.shuffle(subset)\n",
        "    subset = subset[:min(sample_size, len(subset))]\n",
        "\n",
        "    acc1 = 0\n",
        "    rec3 = 0\n",
        "    latencies = []\n",
        "\n",
        "    for r in subset:\n",
        "        t0 = time.perf_counter()\n",
        "        pred = diagnose(r['query'], top_k=3)\n",
        "        dt = time.perf_counter() - t0\n",
        "        latencies.append(dt)\n",
        "\n",
        "        codes = [d.get('icd10_code', '') for d in pred.get('diagnoses', [])]\n",
        "        if codes and codes[0] == r['gt']:\n",
        "            acc1 += 1\n",
        "\n",
        "        valid = set(r.get('icd_codes', []))\n",
        "        if any(c in valid for c in codes[:3]):\n",
        "            rec3 += 1\n",
        "\n",
        "    n = len(subset) or 1\n",
        "    return {\n",
        "        'n': len(subset),\n",
        "        'accuracy_at_1_percent': round(100 * acc1 / n, 2),\n",
        "        'recall_at_3_percent': round(100 * rec3 / n, 2),\n",
        "        'latency_avg_s': round(statistics.mean(latencies), 3) if latencies else None,\n",
        "    }\n",
        "\n",
        "metrics = evaluate_subset(sample_size=20)\n",
        "metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Что дальше для продакшена\n",
        "\n",
        "1. Вынесите `diagnose()` в `src/mock_server.py` (или новый `src/server.py`) как POST `/diagnose`.\n",
        "2. Запустите `evaluate.py` на всем `data/test_set`.\n",
        "3. Для ускорения: кэшируйте ответы LLM и уменьшайте `n_candidates` до 10-15.\n",
        "4. Для качества: добавьте few-shot примеры из похожих кейсов в prompt.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}